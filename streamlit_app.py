import os
import time
import zipfile
import streamlit as st
import pandas as pd
import tempfile
from openpyxl.styles import PatternFill
import shutil

# å¯¼å…¥ç°æœ‰çš„å¤„ç†å‡½æ•°
from all import build_record_index, init_attendance_template, summarize_attendance
from processCCKQ import fill_business_trip
from processLGDJ import fill_leave_registration
from processPCKQ import fill_pc_attendance, process_pc_attendance
from processQJDJ import fill_leave_info
from processShift import fill_shift_attendance
from processYDKQ import fill_oa_attendance

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è€ƒå‹¤åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š è€ƒå‹¤åˆ†æå·¥å…·")

# æ–‡ä»¶ç±»å‹æ˜ å°„ï¼šå…³é”®å­— -> æ–‡ä»¶æè¿°
FILE_TYPE_MAPPING = {
    "é€šä¿¡å½•": "person",
    "OAæ‰“å¡": "oa",
    "å‡ºå·®è®°å½•": "trip",
    "PCè€ƒå‹¤ç»“æœ": "pc",
    "ç¦»å²—ç™»è®°": "leave",
    "å€’ç­è®°å½•": "shift",
    "è¯·å‡è®°å½•": "qj",
    "èŠ‚å‡æ—¥": "holiday",
    "PCæ‰“å¡è®°å½•": "record"
}

# === åœ¨ä¿å­˜æ±‡æ€»è¡¨ä¹‹å‰ï¼Œæ¸…ç† 0 ===
@st.cache_data
def clean_zeros(df):
    return df.applymap(lambda x: "" if (isinstance(x, (int, float)) and x == 0) else x)

# === ä¿å­˜å¸¦é¢œè‰²æ ‡è®°çš„Excelæ–‡ä»¶ ===
def save_excel_with_highlight(df, file_path):
    # åˆ›å»ºExcelWriterå¯¹è±¡
    writer = pd.ExcelWriter(file_path, engine='openpyxl')
    # å°†DataFrameå†™å…¥Excel
    df.to_excel(writer, index=False, sheet_name='Sheet1')
    # è·å–å·¥ä½œè¡¨å¯¹è±¡
    worksheet = writer.sheets['Sheet1']
    
    # æŸ¥æ‰¾'æ˜¯å¦å¼‚å¸¸'åˆ—çš„ç´¢å¼•
    abnormal_col = None
    for col_idx, col_name in enumerate(df.columns):
        if col_name == 'æ˜¯å¦å¼‚å¸¸':
            abnormal_col = col_idx + 1  # openpyxlåˆ—ç´¢å¼•ä»1å¼€å§‹
            break
    
    # å¦‚æœæ‰¾åˆ°'æ˜¯å¦å¼‚å¸¸'åˆ—ï¼Œæ·»åŠ é¢œè‰²æ ‡è®°
    if abnormal_col is not None:
        # åˆ›å»ºå¡«å……æ ·å¼ï¼ˆé»„è‰²èƒŒæ™¯ï¼‰
        fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')
        
        # éå†æ‰€æœ‰è¡Œï¼Œæ ‡è®°'æ˜¯å¦å¼‚å¸¸'ä¸º'æ˜¯'çš„è¡Œ
        for row_idx in range(2, len(df) + 2):  # ä»ç¬¬äºŒè¡Œå¼€å§‹ï¼ˆç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼‰
            cell = worksheet.cell(row=row_idx, column=abnormal_col)
            if cell.value == 'æ˜¯':
                # æ ‡è®°æ•´è¡Œ
                for col in range(1, len(df.columns) + 1):
                    worksheet.cell(row=row_idx, column=col).fill = fill
    
    # ä¿å­˜æ–‡ä»¶
    writer.close()

# === æ‹†åˆ†åŸå§‹æ‰“å¡è®°å½• ===
def split_attendance_records(input_file, output_dir):
    """
    æŒ‰äºŒçº§ç»„ç»‡æ‹†åˆ†è€ƒå‹¤è®°å½•æ–‡ä»¶
    :param input_file: è¾“å…¥çš„è€ƒå‹¤è®°å½•æ–‡ä»¶ï¼ˆCSVæˆ–Excelï¼‰
    :param output_dir: æ‹†åˆ†åæ–‡ä»¶çš„å­˜å‚¨ç›®å½•
    :return: æ‹†åˆ†åçš„æ–‡ä»¶åˆ—è¡¨
    """
    # è¯»å–æ–‡ä»¶
    if input_file.name.endswith('.csv'):
        df = pd.read_csv(input_file, encoding='gbk')
    else:
        df = pd.read_excel(input_file)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # ä»æ‰€å±ç»„ç»‡åˆ—ä¸­æå–äºŒçº§ç»„ç»‡
    df['äºŒçº§ç»„ç»‡'] = df['æ‰€å±ç»„ç»‡'].str.split('/').str[1]
    
    # æŒ‰äºŒçº§ç»„ç»‡åˆ†ç»„å¹¶ä¿å­˜æ–‡ä»¶
    split_files = []
    grouped = df.groupby('äºŒçº§ç»„ç»‡')
    
    for org_name, group in grouped:
        # ç§»é™¤ä¸´æ—¶æ·»åŠ çš„äºŒçº§ç»„ç»‡åˆ—
        group = group.drop(columns=['äºŒçº§ç»„ç»‡'])
        output_file_path = os.path.join(output_dir, f'{org_name}_è€ƒå‹¤è®°å½•.csv')
        group.to_csv(output_file_path, index=False, encoding='utf-8-sig')
        split_files.append(output_file_path)
    
    return split_files

# === åˆ›å»ºZIPæ–‡ä»¶ ===
def create_zip_file(zip_filename, summary_file, detail_file, dept_summary_files, dept_detail_files, split_files=[]):
    with zipfile.ZipFile(zip_filename, 'w') as zipf:
        # æ·»åŠ æ•´ä½“æ±‡æ€»è¡¨å’Œæ˜ç»†è¡¨
        if os.path.exists(summary_file):
            zipf.write(summary_file, os.path.basename(summary_file))
        if os.path.exists(detail_file):
            zipf.write(detail_file, os.path.basename(detail_file))
        
        # æ·»åŠ å„å•ä½æ±‡æ€»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
        for dept_name, file_path in dept_summary_files:
            if os.path.exists(file_path):
                zipf.write(file_path, f"å„å•ä½æ±‡æ€»/{dept_name}_æ±‡æ€».xlsx")
        
        # æ·»åŠ å„å•ä½æ˜ç»†æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
        for dept_name, file_path in dept_detail_files:
            if os.path.exists(file_path):
                zipf.write(file_path, f"å„å•ä½æ˜ç»†/{dept_name}_æ˜ç»†.xlsx")
        
        # æ·»åŠ åŸå§‹æ‰“å¡è®°å½•æ–‡ä»¶å¤¹å’Œæ‹†åˆ†åçš„æ–‡ä»¶
        for file_path in split_files:
            if os.path.exists(file_path):
                file_name = os.path.basename(file_path)
                zipf.write(file_path, f"åŸå§‹æ‰“å¡è®°å½•/{file_name}")

# === æ‰¹é‡æ–‡ä»¶ä¸Šä¼ å¤„ç† ===
def process_uploaded_files(uploaded_files):
    files = {}
    unmatched_files = []
    
    for file in uploaded_files:
        file_name = file.name
        matched = False
        
        for keyword, key in FILE_TYPE_MAPPING.items():
            if keyword in file_name:
                files[key] = file
                matched = True
                break
        
        if not matched:
            unmatched_files.append(file_name)
    
    return files, unmatched_files

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    st.write("è¯·ä¸Šä¼ æ‰€æœ‰è€ƒå‹¤ç›¸å…³æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹")
    
    # æ‰¹é‡æ–‡ä»¶ä¸Šä¼ æ§ä»¶
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        type=["xlsx", "csv"],
        accept_multiple_files=True,
        help="æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªExcelæˆ–CSVæ–‡ä»¶"
    )

with col2:
    st.header("ğŸ“‹ æ–‡ä»¶ç±»å‹è¯´æ˜")
    st.write("è¯·åœ¨æ–‡ä»¶åä¸­åŒ…å«ä»¥ä¸‹å…³é”®å­—ï¼š")
    for keyword, description in FILE_TYPE_MAPPING.items():
        st.write(f"- **{keyword}**: {description}")

# å¤„ç†æ–‡ä»¶ä¸Šä¼ 
if uploaded_files:
    st.subheader("ğŸ“Š æ–‡ä»¶è¯†åˆ«ç»“æœ")
    
    files, unmatched_files = process_uploaded_files(uploaded_files)
    
    # æ˜¾ç¤ºåŒ¹é…çš„æ–‡ä»¶
    if files:
        st.success(f"âœ… æˆåŠŸè¯†åˆ« {len(files)} ä¸ªæ–‡ä»¶")
        for key, file in files.items():
            st.write(f"- **{key}**: {file.name}")
    
    # æ˜¾ç¤ºæœªåŒ¹é…çš„æ–‡ä»¶
    if unmatched_files:
        st.warning(f"âš ï¸ æ— æ³•è¯†åˆ« {len(unmatched_files)} ä¸ªæ–‡ä»¶")
        for file_name in unmatched_files:
            st.write(f"- {file_name}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²ä¸Šä¼ 
    required_keys = ["person", "oa", "trip", "pc", "leave", "shift", "qj", "holiday", "record"]
    missing_keys = [key for key in required_keys if key not in files]
    
    if missing_keys:
        st.error(f"âŒ ç¼ºå°‘ä»¥ä¸‹å¿…éœ€æ–‡ä»¶ï¼š{', '.join(missing_keys)}")
    else:
        st.success("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²ä¸Šä¼ å®Œæˆ")
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'analysis_completed' not in st.session_state:
            st.session_state.analysis_completed = False
        if 'df_summary' not in st.session_state:
            st.session_state.df_summary = None
        if 'df_all' not in st.session_state:
            st.session_state.df_all = None
        if 'dept_summary_files' not in st.session_state:
            st.session_state.dept_summary_files = []
        if 'dept_detail_files' not in st.session_state:
            st.session_state.dept_detail_files = []
        if 'zip_file_created' not in st.session_state:
            st.session_state.zip_file_created = False
        
        # å¼€å§‹åˆ†ææŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", key="start_analysis", help="ç‚¹å‡»å¼€å§‹å¤„ç†è€ƒå‹¤æ•°æ®"):
            with st.spinner("ğŸ• æ­£åœ¨å¤„ç†è€ƒå‹¤æ•°æ®..."):
                try:
                    start_time = time.time()
                    
                    # åŠ è½½æ•°æ®
                    person_df = pd.read_excel(files["person"], dtype={"å·¥å·": str})
                    oa_df = pd.read_excel(files["oa"], dtype={"ç¼–å·": str})
                    leave_df = pd.read_excel(files["leave"], dtype={"äººå‘˜ç¼–ç ": str})
                    qj_df = pd.read_excel(files["qj"], dtype={"å·¥å·": str})
                    holiday_df = pd.read_excel(files["holiday"])
                    holiday_set = set(pd.to_datetime(holiday_df["æ—¥æœŸ"]).dt.date)
                    trip_df = pd.read_excel(files["trip"], dtype={"äººå‘˜ç¼–å·": str})

                    if files["shift"].name.endswith(".xlsx"):
                        shift_df = pd.read_excel(files["shift"], dtype={"å·¥å·": str})
                    else:
                        shift_df = pd.read_csv(files["shift"], encoding="gbk", dtype={"å·¥å·": str})

                    if files["record"].name.endswith(".csv"):
                        record_df = pd.read_csv(files["record"], encoding="gbk", parse_dates=["è€ƒå‹¤æ—¶é—´"], dtype={"å·¥å·": str})
                    else:
                        record_df = pd.read_excel(files["record"], dtype={"å·¥å·": str})

                    # å¤„ç†PCè€ƒå‹¤ç»“æœ
                    date_range, attendance_data = process_pc_attendance(files["pc"])
                    contact_attendance_list, person_dept_dict = init_attendance_template(person_df, date_range[0], date_range[1])
                    index_map = build_record_index(contact_attendance_list)

                    fill_pc_attendance(index_map, attendance_data)
                    fill_oa_attendance(index_map, oa_df)
                    fill_leave_registration(index_map, leave_df)
                    fill_leave_info(index_map, qj_df)
                    fill_business_trip(index_map, trip_df)
                    shift_day_dict = fill_shift_attendance(index_map, shift_df, record_df, holiday_set, person_dept_dict)

                    # æ±‡æ€»æ•°æ®
                    summary_result = summarize_attendance(contact_attendance_list, holiday_set, shift_day_dict)
                    df_summary = pd.DataFrame(summary_result)
                    df_all = pd.DataFrame(contact_attendance_list)

                    # æ¸…ç†æ•°æ®
                    df_summary = clean_zeros(df_summary)
                    
                    # ä¿å­˜å¸¦é¢œè‰²æ ‡è®°çš„æ±‡æ€»è¡¨
                    save_excel_with_highlight(df_summary, "æ±‡æ€»è¡¨.xlsx")
                    
                    # ä¿å­˜å¸¦é¢œè‰²æ ‡è®°çš„æ˜ç»†è¡¨
                    save_excel_with_highlight(df_all, "æ˜ç»†è¡¨.xlsx")
                    
                    # å‡†å¤‡éƒ¨é—¨æ–‡ä»¶åˆ—è¡¨
                    dept_summary_files = []
                    dept_detail_files = []
                    
                    # æŒ‰ä¸€çº§éƒ¨é—¨åˆ†ç»„å¹¶ä¿å­˜æ–‡ä»¶
                    if "éƒ¨é—¨" in df_summary.columns:
                        # æŒ‰ä¸€çº§éƒ¨é—¨åˆ†ç»„
                        dept_groups_summary = df_summary.groupby(df_summary["éƒ¨é—¨"].astype(str).str.split("/").str[0])
                        dept_groups_detail = df_all.groupby(df_all["éƒ¨é—¨"].astype(str).str.split("/").str[0])
                        
                        # ä¸ºæ¯ä¸ªéƒ¨é—¨ä¿å­˜æ–‡ä»¶
                        for dept, group in dept_groups_summary:
                            dept_name = str(dept).strip().replace("/", "_").replace("\\", "_")
                            
                            # ä¿å­˜éƒ¨é—¨æ±‡æ€»è¡¨
                            dept_summary_file = f"{dept_name}_æ±‡æ€».xlsx"
                            save_excel_with_highlight(group, dept_summary_file)
                            dept_summary_files.append((dept_name, dept_summary_file))
                            
                            # ä¿å­˜éƒ¨é—¨æ˜ç»†è¡¨
                            dept_detail_file = f"{dept_name}_æ˜ç»†.xlsx"
                            dept_detail_group = dept_groups_detail.get_group(dept)
                            save_excel_with_highlight(dept_detail_group, dept_detail_file)
                            dept_detail_files.append((dept_name, dept_detail_file))
                    
                    # æ‹†åˆ†åŸå§‹æ‰“å¡è®°å½•
                    split_files = split_attendance_records(files["record"], "åŸå§‹æ‰“å¡è®°å½•")
                    
                    # åˆ›å»ºZIPæ–‡ä»¶
                    create_zip_file("è€ƒå‹¤ç»“æœæ±‡æ€».zip", "æ±‡æ€»è¡¨.xlsx", "æ˜ç»†è¡¨.xlsx", dept_summary_files, dept_detail_files, split_files)
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€
                    st.session_state.analysis_completed = True
                    st.session_state.df_summary = df_summary
                    st.session_state.df_all = df_all
                    st.session_state.dept_summary_files = dept_summary_files
                    st.session_state.dept_detail_files = dept_detail_files
                    st.session_state.split_files = split_files
                    st.session_state.zip_file_created = True
                    
                    # æ˜¾ç¤ºå¤„ç†ç»“æœ
                    st.success("âœ… è€ƒå‹¤æ•°æ®å¤„ç†å®Œæˆï¼")
                    st.write(f"ğŸ“Š å¤„ç†äº† {len(contact_attendance_list)} æ¡è€ƒå‹¤è®°å½•")
                    st.write(f"ğŸ‘¥ æ¶‰åŠ {len(set(df_all['å·¥å·']))} ä½å‘˜å·¥")
                    st.write(f"â±ï¸ ç”¨æ—¶ {time.time() - start_time:.2f} ç§’")
                    
                except Exception as e:
                    st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
                    st.exception(e)
        
        # å¦‚æœåˆ†æå·²å®Œæˆï¼Œæ˜¾ç¤ºä¸‹è½½æŒ‰é’®
        if st.session_state.analysis_completed:
            # æä¾›ä¸‹è½½é“¾æ¥
            st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")
            
            # æä¾›ä¸‹è½½æ•´ä¸ªç»“æœçš„æŒ‰é’®
            if os.path.exists("è€ƒå‹¤ç»“æœæ±‡æ€».zip"):
                with open("è€ƒå‹¤ç»“æœæ±‡æ€».zip", "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½æ•´ä¸ªç»“æœï¼ˆZIPæ ¼å¼ï¼‰",
                        data=f,
                        file_name="è€ƒå‹¤ç»“æœæ±‡æ€».zip",
                        mime="application/zip"
                    )
            
            # æä¾›ä¸‹è½½æ±‡æ€»è¡¨å’Œæ˜ç»†è¡¨çš„æŒ‰é’®
            if os.path.exists("æ±‡æ€»è¡¨.xlsx"):
                with open("æ±‡æ€»è¡¨.xlsx", "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½æ±‡æ€»è¡¨",
                        data=f,
                        file_name="æ‰€æœ‰å•ä½æ±‡æ€»è¡¨.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            
            if os.path.exists("æ˜ç»†è¡¨.xlsx"):
                with open("æ˜ç»†è¡¨.xlsx", "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½æ˜ç»†è¡¨",
                        data=f,
                        file_name="æ‰€æœ‰å•ä½æ˜ç»†è¡¨.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶", key="clean_temp_files"):
                # æ¸…ç†éƒ¨é—¨æ–‡ä»¶
                for dept_name, file_path in st.session_state.dept_summary_files:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                
                for dept_name, file_path in st.session_state.dept_detail_files:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                
                # æ¸…ç†æ‹†åˆ†çš„åŸå§‹æ‰“å¡è®°å½•æ–‡ä»¶
                for file_path in st.session_state.get('split_files', []):
                    if os.path.exists(file_path):
                        os.remove(file_path)
                
                # æ¸…ç†åŸå§‹æ‰“å¡è®°å½•ç›®å½•
                if os.path.exists("åŸå§‹æ‰“å¡è®°å½•"):
                    shutil.rmtree("åŸå§‹æ‰“å¡è®°å½•")
                
                # æ¸…ç†æ±‡æ€»è¡¨å’Œæ˜ç»†è¡¨
                if os.path.exists("æ±‡æ€»è¡¨.xlsx"):
                    os.remove("æ±‡æ€»è¡¨.xlsx")
                
                if os.path.exists("æ˜ç»†è¡¨.xlsx"):
                    os.remove("æ˜ç»†è¡¨.xlsx")
                
                # æ¸…ç†ZIPæ–‡ä»¶
                if os.path.exists("è€ƒå‹¤ç»“æœæ±‡æ€».zip"):
                    os.remove("è€ƒå‹¤ç»“æœæ±‡æ€».zip")
                
                # é‡ç½®ä¼šè¯çŠ¶æ€
                st.session_state.analysis_completed = False
                st.session_state.df_summary = None
                st.session_state.df_all = None
                st.session_state.dept_summary_files = []
                st.session_state.dept_detail_files = []
                st.session_state.split_files = []
                st.session_state.zip_file_created = False
                
                st.success("âœ… ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†å®Œæˆï¼")
                
                # åˆ·æ–°é¡µé¢
                st.rerun()

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.header("â„¹ï¸ å…³äº")
    st.write("è¿™æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„è€ƒå‹¤åˆ†æå·¥å…·ï¼Œä½¿ç”¨Streamlitæ¡†æ¶æ„å»ºã€‚")
    st.write("æ”¯æŒæ‰¹é‡ä¸Šä¼ è€ƒå‹¤æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹ã€‚")
    st.write("ğŸ“… æ›´æ–°æ—¥æœŸï¼š2025-01-01")
    st.write("ğŸ”§ ç‰ˆæœ¬ï¼šv2.0")
